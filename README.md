# **Fine-Tuning Embeddings for Domain-Specific RAG**  

## **Overview**  
This project fine-tunes sentence embeddings to improve retrieval and generation in **Retrieval-Augmented Generation (RAG) systems**. Using **synthetic Q&A pairs** generated by GPT-3.5, we fine-tune `BAAI/bge-small-en` embeddings for better domain-specific retrieval and answer generation.  

## **Key Features**  
- **Fine-tuned embeddings** using domain-specific text (Lyft, Uber annual reports).  
- **Synthetic Q&A generation** with GPT-3.5 for training data.  
- **Retrieval evaluation** using hit rate, precision, MRR, MAP, and NDCG.  
- **RAG evaluation** using a labeled dataset to measure generative performance.  

## **Results**  

| Model               | Precision | Hit Rate | MRR  | MAP  | NDCG |  
|---------------------|-----------|---------|------|------|------|  
| OpenAI (`ada`)      | 0.71  | 0.81  | 0.68 | 0.72 | 0.79 |  
| BAAI/bge-small-en   | 0.69  | 0.79  | 0.65 | 0.70 | 0.77 |  
| **Fine-Tuned Model** | **0.74**  | **0.86** | **0.72** | **0.78** | **0.83** |  

The fine-tuned model outperformed SOTA by **5-6%** in retrieval accuracy.
